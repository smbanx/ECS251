# -*- coding: utf-8 -*-
"""ECS 251 IO Uring Save Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AUgEjD9Qxm29NnRBJ5sFZIxXiLhOGu1M
"""

!pip install datasets

!pip install liburing



import torch
import numpy as np
from datasets import load_dataset
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from transformers import DataCollatorWithPadding
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import os
import pickle
import json



device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

dataset = load_dataset("imdb")


tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

# only do first 100
train_subset = dataset["train"].select(range(100))
test_subset = dataset["test"].select(range(100))

def preprocess_data(examples):
    return tokenizer(examples["text"], truncation=True, padding="max_length", max_length=512)


tokenized_train = train_subset.map(preprocess_data, batched=True)
tokenized_test = test_subset.map(preprocess_data, batched=True)

tokenized_train = tokenized_train.rename_column("label", "labels")
tokenized_test = tokenized_test.rename_column("label", "labels")
tokenized_train.set_format("torch", columns=["input_ids", "attention_mask", "labels"])
tokenized_test.set_format("torch", columns=["input_ids", "attention_mask", "labels"])


model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)
model.to(device)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)


def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    acc = accuracy_score(labels, predictions)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average="binary")
    return {"accuracy": acc, "precision": precision, "recall": recall, "f1": f1}

training_args = TrainingArguments(
    output_dir="./bert_sentiment",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    per_device_train_batch_size=8,  # Adjust if running out of memory
    per_device_eval_batch_size=8,
    num_train_epochs=1,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_steps=500,
    load_best_model_at_end=True,
    save_total_limit=2,
    report_to="none",
    push_to_hub=False,
)


trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_test,
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)


trainer.train()
eval_results = trainer.evaluate()
print("Evaluation Results:", eval_results)

# from the github sample example
from liburing import O_CREAT, O_RDWR, AT_FDCWD, iovec, io_uring, io_uring_get_sqe, \
                     io_uring_prep_openat, io_uring_prep_write, io_uring_prep_read, \
                     io_uring_prep_close, io_uring_submit, io_uring_wait_cqe, \
                     io_uring_cqe_seen, io_uring_cqe, io_uring_queue_init, io_uring_queue_exit, \
                     io_uring_sqe_set_data64, trap_error

def uring_open(ring, cqe, path, flags, mode=0o660, dir_fd=AT_FDCWD):
    _path = path if isinstance(path, bytes) else str(path).encode()
    # if `path` is relative and `dir_fd` is `AT_FDCWD`, then `path` is relative
    # to current working directory. Also `_path` must be in bytes

    sqe = io_uring_get_sqe(ring)  # sqe(submission queue entry)
    io_uring_prep_openat(sqe, _path, flags, mode, dir_fd)
    # set submit entry identifier as `1` which is returned back in `cqe.user_data`
    # so you can keep track of submit/completed entries.
    io_uring_sqe_set_data64(sqe, 1)
    return uring_submit_and_wait(ring, cqe)  # returns fd


def uring_write(ring, cqe, fd, data, offset=0):
    iov = iovec(data)  # or iovec([bytearray(data)])
    sqe = io_uring_get_sqe(ring)
    io_uring_prep_write(sqe, fd, iov.iov_base, iov.iov_len, offset)
    io_uring_sqe_set_data64(sqe, 2)
    return uring_submit_and_wait(ring, cqe)  # returns length(s) of bytes written


def uring_read(ring, cqe, fd, length, offset=0):
    iov = iovec(bytearray(length))  # or [bytearray(length)]
    sqe = io_uring_get_sqe(ring)
    io_uring_prep_read(sqe, fd, iov.iov_base, iov.iov_len, offset)
    io_uring_sqe_set_data64(sqe, 3)
    uring_submit_and_wait(ring, cqe)  # get actual length of file read.
    return iov.iov_base


def uring_close(ring, cqe, fd):
    sqe = io_uring_get_sqe(ring)
    io_uring_prep_close(sqe, fd)
    io_uring_sqe_set_data64(sqe, 4)
    uring_submit_and_wait(ring, cqe)  # no error means success!


def uring_submit_and_wait(ring, cqe):
    io_uring_submit(ring)  # submit entry
    io_uring_wait_cqe(ring, cqe)  # wait for entry to finish
    result = trap_error(cqe.res)  # auto raise appropriate exception if failed
    # note `cqe.res` returns results, if ``< 0`` its an error, if ``>= 0`` its the value

    # done with current entry so clear it from completion queue.
    io_uring_cqe_seen(ring, cqe)
    return result  # type: int



ring = io_uring()
cqe = io_uring_cqe()
io_uring_queue_init(32, ring, 0)
fd = uring_open(ring, cqe, 'model.pkl', O_CREAT | O_RDWR)
data_bytes = pickle.dumps(model.state_dict())
uring_write(ring, cqe, fd, data_bytes)
uring_close(ring, cqe, fd)
io_uring_queue_exit(ring)

ring = io_uring()
cqe = io_uring_cqe()
io_uring_queue_init(32, ring, 0)
fd = uring_open(ring, cqe, 'vocab.txt', O_CREAT | O_RDWR)
byte_data = json.dumps(tokenizer.get_vocab()).encode('utf-8')
uring_write(ring, cqe, fd, byte_data)
uring_close(ring, cqe, fd)
io_uring_queue_exit(ring)